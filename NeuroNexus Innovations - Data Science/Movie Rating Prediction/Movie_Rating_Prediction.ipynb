{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Python code is a data preprocessing and modeling pipeline for analyzing IMDb movie ratings.\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/adrianmcmahon/imdb-india-movies"
      ],
      "metadata": {
        "id": "W0nRfFU7E5Xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries\n",
        "- The code imports necessary libraries including pandas for data manipulation, scikit-learn for machine learning tools, and modules such as RandomForestRegressor, DecisionTreeRegressor, mean_squared_error, SimpleImputer, ColumnTransformer, and OneHotEncoder."
      ],
      "metadata": {
        "id": "hd99vZq_E7FW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVx_X8v8EvrF",
        "outputId": "9a343e33-7f56-4a42-8c21-372252947c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Data Preprocessing\n",
        "1. **Loading Data**: It loads the IMDb movies data from a CSV file into a pandas DataFrame. During loading, it handles non-numeric columns by specifying certain values to be treated as missing values.\n",
        "   \n",
        "2. **Handling Non-Numeric Values in 'Year' and 'Duration'**: It extracts the numeric values from the 'Year' and 'Duration' columns and converts them to float data type.\n",
        "\n",
        "3. **Handling Missing Values**: It uses SimpleImputer from scikit-learn to fill missing values in the 'Year' and 'Duration' columns with their mean values.\n",
        "\n",
        "4. **Defining Features and Target**: It defines the feature matrix (X) containing columns like 'Year', 'Duration', 'Genre', 'Director', and actors, and sets the target variable (y) as 'Rating', converted to float data type.\n",
        "\n",
        "5. **Splitting Data**: It splits the data into training and testing sets using train_test_split from scikit-learn.\n",
        "\n",
        "6. **Encoding Categorical Columns**: It uses ColumnTransformer with OneHotEncoder to encode the categorical columns ('Genre', 'Director', 'Actor 1', 'Actor 2', 'Actor 3') while keeping other columns unchanged."
      ],
      "metadata": {
        "id": "me8dIzupE_Lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Preprocessing\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Neuronexus Innovations/NeuroNexus Innovations - Data Science/Movie Rating Prediction/IMDb Movies India.csv'\n",
        "\n",
        "# Load the data and handle non-numeric columns during data loading\n",
        "movie_data = pd.read_csv(file_path, encoding='latin1', na_values=['N/A', 'NA', 'NaN'])\n",
        "\n",
        "# Extract numeric values from 'Year' and 'Duration' columns\n",
        "movie_data['Year'] = movie_data['Year'].str.extract('(\\d+)').astype(float)\n",
        "movie_data['Duration'] = movie_data['Duration'].str.extract('(\\d+)').astype(float)\n",
        "\n",
        "# Handle missing values using SimpleImputer for numerical columns\n",
        "numerical_cols = ['Year', 'Duration']\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "movie_data[numerical_cols] = imputer.fit_transform(movie_data[numerical_cols])\n",
        "\n",
        "# Define the feature matrix (X) and the target variable (y)\n",
        "X = movie_data[['Year', 'Duration', 'Genre', 'Director', 'Actor 1', 'Actor 2', 'Actor 3']]\n",
        "y = movie_data['Rating'].astype(float)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use ColumnTransformer to apply OneHotEncoder to the categorical columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Genre', 'Director', 'Actor 1', 'Actor 2', 'Actor 3'])\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform the preprocessor on the training data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# Transform the testing data using the preprocessor fitted on the training data\n",
        "X_test_preprocessed = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "u8XkPrqzFCOE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Modeling\n",
        "1. **Initializing and Fitting Models**: It initializes two models, Random Forest and Decision Tree regressors, and fits them using the preprocessed training data.\n",
        "   \n",
        "2. **Model Evaluation**: It calculates Mean Squared Error (MSE) for each model's predictions on the test data and stores the evaluation metrics in a results dictionary.\n",
        "\n",
        "3. **Printing Results**: It prints the model names and their corresponding mean squared errors."
      ],
      "metadata": {
        "id": "e0Ad3SLDFRuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Modeling\n",
        "# Initialize and fit the models\n",
        "models = {\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Decision Tree': DecisionTreeRegressor()\n",
        "}\n",
        "\n",
        "# Results dictionary to store model evaluation metrics\n",
        "results = {}\n",
        "\n",
        "# Handle missing values in the target variable using SimpleImputer\n",
        "y_imputer = SimpleImputer(strategy='mean')\n",
        "y_train_imputed = y_imputer.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
        "y_test_imputed = y_imputer.transform(y_test.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Use the imputed target variable for modeling\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train_preprocessed, y_train_imputed)\n",
        "    y_pred = model.predict(X_test_preprocessed)\n",
        "\n",
        "    mse = mean_squared_error(y_test_imputed, y_pred)\n",
        "\n",
        "    # Store predictions and other relevant information for further analysis\n",
        "    results[model_name] = {\n",
        "        'mean_squared_error': mse,\n",
        "        'predictions': y_pred\n",
        "        # Additional information can be added here for comprehensive analysis\n",
        "    }\n",
        "\n",
        "# Print results for each model\n",
        "for model_name, result in results.items():\n",
        "    print(f\"Results for {model_name}:\")\n",
        "    print(\"Mean Squared Error:\", result['mean_squared_error'])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SbHIy-vFVrc",
        "outputId": "925a8c37-32c6-4c1d-cd8c-ed4f217a4ea2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Random Forest:\n",
            "Mean Squared Error: 0.8023782412474423\n",
            "\n",
            "\n",
            "Results for Decision Tree:\n",
            "Mean Squared Error: 1.1008900312837027\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, this code performs data preprocessing, encoding categorical variables, training models, and evaluating their performance using mean squared error as the metric."
      ],
      "metadata": {
        "id": "0IM3XDpsFXit"
      }
    }
  ]
}