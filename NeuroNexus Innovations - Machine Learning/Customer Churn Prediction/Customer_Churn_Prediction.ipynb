{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Python code is for building, tuning, and evaluating machine learning models using the scikit-learn library.\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/shantanudhakadd/bank-customer-churn-prediction"
      ],
      "metadata": {
        "id": "M7iK8Jk_nWml"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KoUjWBwEm80H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d3b224-46b4-4e5a-b2da-11d0df9ee4a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Data Exploration\n",
        "- Loads the dataset from the file `Churn_Modelling.csv`\n",
        "- Displays the first few rows of the dataset\n",
        "- Provides information about the dataset (e.g., column data types, non-null counts)\n",
        "- Describes the statistical summary of the numerical features in the dataset"
      ],
      "metadata": {
        "id": "NvS6wVLAP8sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Neuronexus Innovations/Neuronexus Innovations - Machine Learning/Customer Churn Prediction/Churn_Modelling.csv')\n",
        "\n",
        "# Exploring the data\n",
        "print('\\n', data.head())\n",
        "print('\\n', data.info())\n",
        "print('\\n', data.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLr89C2OP8Ti",
        "outputId": "10bec9ab-6887-4260-ea59-010985ba7b07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
            "0          1    15634602  Hargrave          619    France  Female   42   \n",
            "1          2    15647311      Hill          608     Spain  Female   41   \n",
            "2          3    15619304      Onio          502    France  Female   42   \n",
            "3          4    15701354      Boni          699    France  Female   39   \n",
            "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
            "\n",
            "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
            "0       2       0.00              1          1               1   \n",
            "1       1   83807.86              1          0               1   \n",
            "2       8  159660.80              3          1               0   \n",
            "3       1       0.00              2          0               0   \n",
            "4       2  125510.82              1          1               1   \n",
            "\n",
            "   EstimatedSalary  Exited  \n",
            "0        101348.88       1  \n",
            "1        112542.58       0  \n",
            "2        113931.57       1  \n",
            "3         93826.63       0  \n",
            "4         79084.10       0  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n",
            "\n",
            " None\n",
            "\n",
            "          RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
            "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
            "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
            "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
            "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
            "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
            "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
            "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
            "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
            "\n",
            "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
            "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
            "mean    76485.889288       1.530200      0.70550        0.515100   \n",
            "std     62397.405202       0.581654      0.45584        0.499797   \n",
            "min         0.000000       1.000000      0.00000        0.000000   \n",
            "25%         0.000000       1.000000      0.00000        0.000000   \n",
            "50%     97198.540000       1.000000      1.00000        1.000000   \n",
            "75%    127644.240000       2.000000      1.00000        1.000000   \n",
            "max    250898.090000       4.000000      1.00000        1.000000   \n",
            "\n",
            "       EstimatedSalary        Exited  \n",
            "count     10000.000000  10000.000000  \n",
            "mean     100090.239881      0.203700  \n",
            "std       57510.492818      0.402769  \n",
            "min          11.580000      0.000000  \n",
            "25%       51002.110000      0.000000  \n",
            "50%      100193.915000      0.000000  \n",
            "75%      149388.247500      0.000000  \n",
            "max      199992.480000      1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Feature Engineering\n",
        "- Identifies important features that could potentially influence customer churn\n",
        "- No specific feature engineering steps are added in this code"
      ],
      "metadata": {
        "id": "u2u11oAJQHPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Feature Engineering (if required)\n",
        "# Identify important features that could potentially influence customer churn\n",
        "# Add feature engineering steps if necessary based on the dataset and problem at hand"
      ],
      "metadata": {
        "id": "2YZBUYesQMGi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Data Preprocessing\n",
        "- Splits the data into features (X) and the target variable (y)\n",
        "- Splits the data into training and testing sets using a 80-20 split ratio"
      ],
      "metadata": {
        "id": "fKefdqDTQO50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['RowNumber', 'CustomerId', 'Surname', 'Exited'])  # Features\n",
        "y = data['Exited']  # Target variable\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OTmTRx1WQRv7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Model Building\n",
        "- Defines three pipelines for three different classifiers: Random Forest, Logistic Regression, and Gradient Boosting\n",
        "- Each pipeline includes a preprocessing step using `ColumnTransformer` to scale numerical features and one-hot encode categorical features\n",
        "- The classifiers used are RandomForestClassifier, LogisticRegression, and GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "EmFvGkRwQV_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Random Forest, Logistic Regression, and Gradient Boosting classifiers\n",
        "model_rf = Pipeline(steps=[\n",
        "    ('preprocessor', ColumnTransformer(transformers=[\n",
        "        ('num', StandardScaler(), ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']),\n",
        "        ('cat', OneHotEncoder(), ['Geography', 'Gender'])\n",
        "    ])),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "model_lr = Pipeline(steps=[\n",
        "    ('preprocessor', ColumnTransformer(transformers=[\n",
        "        ('num', StandardScaler(), ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']),\n",
        "        ('cat', OneHotEncoder(), ['Geography', 'Gender'])\n",
        "    ])),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "model_gb = Pipeline(steps=[\n",
        "    ('preprocessor', ColumnTransformer(transformers=[\n",
        "        ('num', StandardScaler(), ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']),\n",
        "        ('cat', OneHotEncoder(), ['Geography', 'Gender'])\n",
        "    ])),\n",
        "    ('classifier', GradientBoostingClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "Y6oldpamQYO0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Hyperparameter Tuning\n",
        "- For each classifier, it conducts hyperparameter tuning using `GridSearchCV` to find the best hyperparameters based on accuracy\n",
        "- It prints the best hyperparameters for each classifier\n",
        "\n",
        "### Step 6: Model Evaluation\n",
        "- Evaluates each classifier's performance using metrics such as Accuracy, Precision, Recall, F1 Score, and ROC AUC\n",
        "- Prints the evaluation results for each classifier"
      ],
      "metadata": {
        "id": "jbbxtXtcQccD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Hyperparameter Tuning for Random Forest Classifier\n",
        "param_grid_rf = {\n",
        "    'classifier__n_estimators': [100, 200, 300],\n",
        "    'classifier__max_depth': [10, 20, 30, None]\n",
        "}\n",
        "grid_search_rf = GridSearchCV(model_rf, param_grid_rf, cv=5, scoring='accuracy').fit(X_train, y_train)\n",
        "best_params_rf = grid_search_rf.best_params_\n",
        "print(\"\\nBest Hyperparameters for Random Forest Classifier:\", best_params_rf)\n",
        "\n",
        "# Step 6: Model Evaluation for Random Forest Classifier\n",
        "best_model_rf = grid_search_rf.best_estimator_\n",
        "y_pred_rf = best_model_rf.predict(X_test)\n",
        "metrics_rf = {\n",
        "    'Accuracy RF': accuracy_score,\n",
        "    'Precision RF': precision_score,\n",
        "    'Recall RF': recall_score,\n",
        "    'F1 Score RF': f1_score,\n",
        "    'ROC AUC RF': roc_auc_score\n",
        "}\n",
        "results_rf = {metric: score(y_test, y_pred_rf) for metric, score in metrics_rf.items()}\n",
        "print(\"\\n\", results_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu3Z2OEYQfvE",
        "outputId": "5f901177-ce5b-4c03-abd8-1497d976f8d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters for Random Forest Classifier: {'classifier__max_depth': 30, 'classifier__n_estimators': 300}\n",
            "\n",
            " {'Accuracy RF': 0.8655, 'Precision RF': 0.748, 'Recall RF': 0.4758269720101781, 'F1 Score RF': 0.5816485225505444, 'ROC AUC RF': 0.718311743627989}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Hyperparameter Tuning for Logistic Regression\n",
        "param_grid_lr = {'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "grid_search_lr = GridSearchCV(model_lr, param_grid_lr, cv=5, scoring='accuracy').fit(X_train, y_train)\n",
        "best_params_lr = grid_search_lr.best_params_\n",
        "print(\"\\nBest Hyperparameters for Logistic Regression:\", best_params_lr)\n",
        "\n",
        "# Step 6: Model Evaluation for Logistic Regression\n",
        "best_model_lr = grid_search_lr.best_estimator_\n",
        "y_pred_lr = best_model_lr.predict(X_test)\n",
        "metrics_lr = {\n",
        "    'Accuracy LR': accuracy_score,\n",
        "    'Precision LR': precision_score,\n",
        "    'Recall LR': recall_score,\n",
        "    'F1 Score LR': f1_score,\n",
        "    'ROC AUC LR': roc_auc_score\n",
        "}\n",
        "results_lr = {metric: score(y_test, y_pred_lr) for metric, score in metrics_lr.items()}\n",
        "print(\"\\n\", results_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI-3-GHiQi1i",
        "outputId": "fb04d481-addf-4712-9130-50247ea4ab27"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters for Logistic Regression: {'classifier__C': 10}\n",
            "\n",
            " {'Accuracy LR': 0.811, 'Precision LR': 0.5524475524475524, 'Recall LR': 0.2010178117048346, 'F1 Score LR': 0.2947761194029851, 'ROC AUC LR': 0.5805960247074267}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Hyperparameter Tuning for Gradient Boosting Classifier\n",
        "param_grid_gb = {\n",
        "    'classifier__n_estimators': [100, 200, 300],\n",
        "    'classifier__learning_rate': [0.05, 0.1, 0.2],\n",
        "    'classifier__max_depth': [3, 4, 5]\n",
        "}\n",
        "grid_search_gb = GridSearchCV(model_gb, param_grid_gb, cv=5, scoring='accuracy').fit(X_train, y_train)\n",
        "best_params_gb = grid_search_gb.best_params_\n",
        "print(\"\\nBest Hyperparameters for Gradient Boosting Classifier:\", best_params_gb)\n",
        "\n",
        "# Step 6: Model Evaluation for Gradient Boosting Classifier\n",
        "best_model_gb = grid_search_gb.best_estimator_\n",
        "y_pred_gb = best_model_gb.predict(X_test)\n",
        "metrics_gb = {\n",
        "    'Accuracy GB': accuracy_score,\n",
        "    'Precision GB': precision_score,\n",
        "    'Recall GB': recall_score,\n",
        "    'F1 Score GB': f1_score,\n",
        "    'ROC AUC GB': roc_auc_score\n",
        "}\n",
        "results_gb = {metric: score(y_test, y_pred_gb) for metric, score in metrics_gb.items()}\n",
        "print(\"\\n\", results_gb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj1qwbagQk3-",
        "outputId": "c0dfb81d-830c-4d98-f6b0-a37620c4115f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters for Gradient Boosting Classifier: {'classifier__learning_rate': 0.05, 'classifier__max_depth': 5, 'classifier__n_estimators': 100}\n",
            "\n",
            " {'Accuracy GB': 0.867, 'Precision GB': 0.7509881422924901, 'Recall GB': 0.48346055979643765, 'F1 Score GB': 0.588235294117647, 'ROC AUC GB': 0.7221285375211186}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Deployment\n",
        "- Placeholder comment for future deployment of the best model to make predictions on new customer data"
      ],
      "metadata": {
        "id": "KadjFD2EQogB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Deployment\n",
        "# Deploy the best model to make predictions on new customer data\n",
        "# Include deployment steps as per your specific deployment requirements"
      ],
      "metadata": {
        "id": "lW-fDSReQoQa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code demonstrates a structured approach to building, tuning, and evaluating machine learning models for predicting customer churn. It adheres to the best practices for preprocessing, model selection, and performance evaluation."
      ],
      "metadata": {
        "id": "JlImuXvHQrvD"
      }
    }
  ]
}